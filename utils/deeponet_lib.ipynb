{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpCYbS0jd/a42CcHHxQ3cl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uRL6Uo0ujtbb","executionInfo":{"status":"ok","timestamp":1743928383187,"user_tz":-120,"elapsed":17606,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Subset\n","import gdown\n","from IPython.display import clear_output as clc"]},{"cell_type":"code","source":["try:\n","     from dlroms import*\n","except:\n","     !pip install git+https://github.com/NicolaRFranco/dlroms.git\n","     from dlroms import*"],"metadata":{"id":"lWKpQn-R6DuI","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"id":"O8N8pDhEqjV7","executionInfo":{"status":"aborted","timestamp":1743928399481,"user_tz":-120,"elapsed":34043,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DeepONet(nn.Module):\n","  def __init__(self, m, d, p, h):\n","      \"\"\"\n","      Parameters\n","      ----------\n","      m : int\n","          dimension for the input parameters\n","      d : int\n","          dimension for the input data\n","      p : int\n","          dimension of branch and trunk networks output\n","      h : int\n","          number of neurons in hidden layers\n","      \"\"\"\n","      super().__init__()\n","\n","      self.branch = nn.Sequential(\n","          nn.Linear(m, h),\n","          nn.ReLU(),\n","          nn.Linear(h, h),\n","          nn.ReLU(),\n","          nn.Linear(h, p)\n","      )\n","      self.trunk = nn.Sequential(\n","          nn.Linear(d, h),\n","          nn.ReLU(),\n","          nn.Linear(h, h),\n","          nn.ReLU(),\n","          nn.Linear(h, p)\n","      )\n","\n","  def forward(self, u, y):\n","      b = self.branch(u)  # Shape: (batch_size, p)\n","      b = b.unsqueeze(1)  # New shape: (batch_size, 1, p)\n","      t = self.trunk(y)   # Shape: (batch_size, 1681, p)\n","\n","      #print(f\"b.shape: {b.shape}, t.shape: {t.shape}\")\n","\n","      Gu = torch.sum(b * t, dim=-1) # Shape: (batch_size, 1681)\n","      #print(f\"Gu.shape: {Gu.shape}\")\n","\n","      return Gu"],"metadata":{"id":"8xcUGxtzor-k","executionInfo":{"status":"aborted","timestamp":1743928399493,"user_tz":-120,"elapsed":34052,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data\n","class FomDataset(Dataset):\n","  def __init__(self, mu, u, y):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    mu : int\n","    input parameters, referred as u in the DeepONet paper and in the above model\n","    u : int\n","    solution of the PDE, referred as G(u) in the DeepONet paper and in the above model\n","    y : int\n","    spatial domain coordinate, referred as y in the DeepONet paper and in the above model\n","    \"\"\"\n","    self.mu = torch.tensor(mu, dtype=torch.float32).to(device)\n","    self.u = torch.tensor(u, dtype=torch.float32).to(device)\n","    self.y = torch.tensor(y, dtype=torch.float32).to(device)\n","\n","  def __len__(self):\n","    return len(self.mu)\n","\n","  def __getitem__(self, idx):\n","    return self.mu[idx], self.u[idx], self.y\n","\n","def train_val_test_split(dataset, train_size, val_size):\n","    \"\"\"\n","    Splits a dataset into training, validation, and test subsets.\n","\n","    Parameters\n","    ----------\n","    dataset : FomDataset\n","        The full dataset.\n","    train_size : int\n","        Total number of training samples (includes validation).\n","    val_size : int\n","        Number of validation samples.\n","    \"\"\"\n","    train_indices = list(range(0, train_size - val_size))\n","    val_indices = list(range(train_size - val_size, train_size))\n","    test_indices = list(range(train_size, len(dataset)))\n","\n","    train_set = Subset(dataset, train_indices)\n","    val_set = Subset(dataset, val_indices)\n","    test_set = Subset(dataset, test_indices)\n","\n","    return train_set, val_set, test_set\n","\n","from torch.utils.data import Subset\n","\n","def train_val_test_split2(dataset, test_size):\n","    \"\"\"\n","    Splits a dataset into training, validation, and test subsets.\n","\n","    Parameters\n","    ----------\n","    dataset : FomDataset\n","        The full dataset.\n","    test_size : int\n","        Total number of test samples.\n","    \"\"\"\n","    total_size = len(dataset)\n","    test_indices = list(range(total_size - test_size, total_size))\n","\n","    # Remaining data for training and validation\n","    remaining_indices = list(range(0, total_size - test_size))\n","\n","    # Calculate train and validation split\n","    train_size = int(0.9 * len(remaining_indices))  # 90% for training\n","    val_size = len(remaining_indices) - train_size  # Remaining 10% for validation\n","\n","    train_indices = remaining_indices[:train_size]\n","    val_indices = remaining_indices[train_size:]\n","\n","    # Create subsets\n","    train_set = Subset(dataset, train_indices)\n","    val_set = Subset(dataset, val_indices)\n","    test_set = Subset(dataset, test_indices)\n","\n","    return train_set, val_set, test_set\n"],"metadata":{"id":"FlRRPTe6bewm","executionInfo":{"status":"aborted","timestamp":1743928399705,"user_tz":-120,"elapsed":60,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(id):\n","  gdown.download(id = id, output = \"data.npz\")\n","  data = np.load(\"data.npz\")\n","  mu, u = data['mu'].copy(), data['u'].copy()\n","  return mu, u\n","\n","def get_fem_space(custom_mesh = None):\n","  if custom_mesh is None:\n","    mesh = fe.unitsquaremesh(40, 40)\n","  else:\n","    mesh = custom_mesh\n","  Vh = fe.space(mesh, 'CG', 1)\n","  y = fe.coordinates(Vh)\n","  return Vh, y"],"metadata":{"id":"dp5Yc0wt8UHM","executionInfo":{"status":"aborted","timestamp":1743928399707,"user_tz":-120,"elapsed":61,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training\n","class Trainer:\n","  def __init__(self, train_loader, val_loader, test_loader, model, loss_function, optimizer, epochs, error_metric = None, verbose=False):\n","    self.train_loader = train_loader\n","    self.val_loader = val_loader\n","    self.test_loader = test_loader\n","    self.model = model\n","    self.loss_function = loss_function\n","    self.error_metric = error_metric\n","    self.optimizer = optimizer\n","    self.epochs = epochs\n","    self.verbose = verbose\n","\n","    self.train_hist = {\"loss\": [], \"error_metric\": []}\n","    self.val_hist = {\"loss\": [], \"error_metric\": []}\n","    self.test_hist = {\"loss\": [], \"error_metric\": []}\n","\n","\n","  def train_step(self):\n","    \"\"\"\n","    Perform a single training step in the optimization loop\n","    \"\"\"\n","    train_size = len(self.train_loader.dataset)\n","    num_batches = len(self.train_loader)\n","    batch_size =  train_loader.batch_size\n","    total_loss = 0.0  # Accumulate loss for reporting\n","    total_error_metric = 0.0\n","\n","    self.model.train()\n","    for batch_idx, (mu, u, y) in enumerate(self.train_loader):\n","\n","      # Predict\n","      Gu_pred = self.model(mu,y)\n","      loss = self.loss_function(Gu_pred, u) # The optimizer updates weights batch-by-batch in sgd so we don't need to accumolate it for final reporting\n","      total_loss += loss.item()\n","      if(self.error_metric is not None):\n","        metric = self.error_metric(Gu_pred, u)\n","        total_error_metric += metric.item()\n","\n","      # Backpropagation\n","      self.optimizer.zero_grad()\n","      loss.backward()\n","      self.optimizer.step()\n","\n","      # Print training stats\n","      if (batch_idx % 10 == 0):\n","        loss_value, current_sample = loss.item(), batch_idx * batch_size + len(mu)\n","        print(f\"\\rCurrent Loss: {loss_value:>7f}  [{current_sample:>5d}/{train_size:>5d}]\", end=\"\", flush=True)\n","\n","    avg_loss = total_loss / num_batches  # Compute average loss for the epoch\n","    avg_error_metric = total_error_metric / num_batches\n","\n","\n","    return avg_loss, avg_error_metric # return the avg train loss at the end of the epoch\n","\n","  def validation_step(self):\n","    \"\"\"\n","    Perform a single validation step in the optimization loop\n","    \"\"\"\n","    num_batches = len(self.val_loader)\n","    total_loss = 0.0\n","    total_error_metric = 0.0\n","\n","    self.model.eval()\n","    with torch.no_grad():\n","      for batch_idx, (mu, u, y) in enumerate(self.val_loader):\n","        #Predict\n","        Gu_pred = self.model(mu,y)\n","        loss = self.loss_function(Gu_pred, u)\n","        total_loss += loss.item()\n","        if(self.error_metric is not None):\n","          metric = self.error_metric(Gu_pred, u)\n","          total_error_metric += metric.item()\n","\n","      avg_loss = total_loss / num_batches\n","      avg_error_metric = total_error_metric / num_batches\n","\n","      return avg_loss, avg_error_metric\n","\n","  def test_step(self):\n","    \"\"\"\n","    Perform a single test step in the optimization loop\n","    \"\"\"\n","    num_batches = len(self.test_loader)\n","    total_loss = 0.0\n","    total_error_metric = 0.0\n","\n","    self.model.eval()\n","    with torch.no_grad():\n","      for batch_idx, (mu, u, y) in enumerate(self.test_loader):\n","        #Predict\n","        Gu_pred = self.model(mu,y)\n","        loss = self.loss_function(Gu_pred, u)\n","        total_loss += loss.item()\n","        if(self.error_metric is not None):\n","          metric = self.error_metric(Gu_pred, u)\n","          total_error_metric += metric.item()\n","\n","    avg_loss = total_loss / num_batches\n","    avg_error_metric = total_error_metric / num_batches\n","\n","    return avg_loss, avg_error_metric\n","\n","  def fit(self):\n","    \"\"\"\n","    Perform the optimization loop over the specified number of epochs.\n","    \"\"\"\n","    for epoch in range(self.epochs):\n","      print(f\"Epoch {epoch+1}/{self.epochs}:\")\n","\n","      # Run train, validation, and test steps\n","      train_loss, train_err_metric = self.train_step()\n","      val_loss, val_err_metric = self.validation_step()\n","      test_loss, test_err_metric = self.test_step()\n","\n","      # Save history\n","      self.train_hist[\"loss\"].append(train_loss), self.val_hist[\"loss\"].append(val_loss), self.test_hist[\"loss\"].append(test_loss)\n","      if(self.error_metric is not None):\n","        self.train_hist[\"error_metric\"].append(train_err_metric), self.val_hist[\"error_metric\"].append(val_err_metric), self.test_hist[\"error_metric\"].append(test_err_metric)\n","\n","      # Print formatted progress\n","      print(f\"\\nTrain Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Test Loss: {test_loss:.4f}\")\n","      if(self.error_metric is not None and self.verbose):\n","        print(f\"Train Error Metric: {train_err_metric:.4f} | Val Error Metric: {val_err_metric:.4f} | Test Error Metric: {test_err_metric:.4f}\")\n","\n","    print(\"Done!\")\n","\n","    return self.train_hist, self.val_hist, self.test_hist"],"metadata":{"id":"w4fpONtAR-5F","executionInfo":{"status":"aborted","timestamp":1743928399709,"user_tz":-120,"elapsed":62,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loss and Metric definitions\n","def mse_loss(true, predicted):\n","  return (true-predicted).pow(2).mean(axis = -1).mean()\n","\n","def error_metric(true, predicted):\n","  return ((true-predicted).abs().mean(axis = -1)/true.abs().mean(axis = -1)).mean()"],"metadata":{"id":"IPqZUbJWxNVb","executionInfo":{"status":"aborted","timestamp":1743928399711,"user_tz":-120,"elapsed":62,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting Utilities\n","def plot_loss(trainer):\n","  n_epochs = trainer.epochs\n","  train_hist, val_hist, test_hist = trainer.train_hist['loss'], trainer.val_hist['loss'], trainer.test_hist['loss']\n","  plt.figure(figsize = (5, 3))\n","  plt.semilogx(train_hist, '-k', label = 'Train')\n","  plt.semilogx(val_hist, '--b', label = 'Validation')\n","  plt.semilogx(test_hist, '--r', label = 'Test')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.axis([0.5, n_epochs, 0, 0.075])\n","  plt.legend()\n","  plt.show()\n","\n","def plot_error_metric(trainer):\n","  n_epochs = trainer.epochs\n","  train_hist, val_hist, test_hist = trainer.train_hist['error_metric'], trainer.val_hist['error_metric'], trainer.test_hist['error_metric']\n","  plt.figure(figsize = (5, 3))\n","  plt.semilogx(train_hist, '-k', label = 'Train')\n","  plt.semilogx(val_hist, '--b', label = 'Validation')\n","  plt.semilogx(test_hist, '--r', label = 'Test')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('MRE')\n","  plt.axis([0.5, n_epochs, 0, 0.075])\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"wuGVAIoIIPdr","executionInfo":{"status":"aborted","timestamp":1743928399714,"user_tz":-120,"elapsed":63,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_errors(trainer, ymax_loss, ymax_metric):\n","    n_epochs = trainer.epochs\n","\n","    # Plot Loss\n","    plt.figure(figsize=(10, 4))  # Wider figure for side-by-side plots\n","\n","    plt.subplot(1, 2, 1)\n","    train_loss = trainer.train_hist['loss']\n","    val_loss = trainer.val_hist['loss']\n","    test_loss = trainer.test_hist['loss']\n","    plt.semilogx(train_loss, '-k', label='Train')\n","    plt.semilogx(val_loss, '--b', label='Validation')\n","    plt.semilogx(test_loss, '--r', label='Test')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Loss')\n","    plt.axis([0.5, n_epochs, 0, ymax_loss])\n","    plt.legend()\n","\n","    # Plot Error Metric if available\n","    if trainer.error_metric is not None:\n","        plt.subplot(1, 2, 2)\n","        train_metric = trainer.train_hist['error_metric']\n","        val_metric = trainer.val_hist['error_metric']\n","        test_metric = trainer.test_hist['error_metric']\n","        plt.semilogx(train_metric, '-k', label='Train')\n","        plt.semilogx(val_metric, '--b', label='Validation')\n","        plt.semilogx(test_metric, '--r', label='Test')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('MRE')\n","        plt.title('Error Metric')\n","        plt.axis([0.5, n_epochs, 0, ymax_metric])\n","        plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"Lv52peVCxWzR","executionInfo":{"status":"aborted","timestamp":1743928399717,"user_tz":-120,"elapsed":65,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_solution(mu, u, Vh):\n","  clc()\n","  fe.plot(u, Vh)\n","  plt.title(\"Solution for $\\mu$ = [%.2f,%.2f,%.2f]\" % tuple(mu))\n","  None\n","\n","def add_batch_dimension(test_sample):\n","    # Add batch dimension to the test_sample\n","    mu, true_u, y = test_sample\n","    mu = mu.unsqueeze(0)\n","    true_u = true_u.unsqueeze(0)\n","    y = y.unsqueeze(0)\n","    return mu, true_u, y\n","\n","def compare_solutions(test_sample, Vh):\n","    # Add batch dimension\n","    mu, true_u, y = add_batch_dimension(test_sample)\n","\n","    # Get the predicted solution\n","    pred_u = model(mu, y).squeeze(0)  # Remove batch dimension for plotting\n","\n","    # Ensure the solutions are numpy arrays\n","    true_u = true_u.squeeze(0).detach().numpy()  # Convert to numpy array\n","    pred_u = pred_u.detach().numpy()  # Convert to numpy array\n","\n","    # Plot the true and predicted solutions\n","    clc()  # If you are using Matlab-like syntax for clearing console output (optional)\n","    plt.figure(figsize=(10, 5))\n","\n","    vmin, vmax = true_u.min(), true_u.max()\n","\n","    plt.subplot(1, 2, 1)\n","    plt.title(\"True solution\")\n","    fe.plot(true_u, Vh, colorbar=True, vmin=vmin, vmax=vmax, shrink=0.7)\n","\n","    plt.subplot(1, 2, 2)\n","    plt.title(\"DeepONet approximation\")\n","    fe.plot(pred_u, Vh, colorbar=True, vmin=vmin, vmax=vmax, shrink=0.7)\n","\n","    plt.show()"],"metadata":{"id":"pAYYeGeH00sr","executionInfo":{"status":"aborted","timestamp":1743928399719,"user_tz":-120,"elapsed":65,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compare_solutions_scalar(test_sample):\n","  # Add batch dimension\n","  mu, true_u, y = add_batch_dimension(test_sample)\n","\n","  # Get the predicted solution\n","  pred_u = model(mu, y).squeeze(0)  # Remove batch dimension for plotting\n","\n","  # Ensure the solutions are numpy arrays\n","  true_u = true_u.squeeze(0).detach().numpy()  # Convert to numpy array\n","  pred_u = pred_u.detach().numpy()  # Convert to numpy array\n","\n","  # Plot the true and predicted solutions\n","  clc()  # If you are using Matlab-like syntax for clearing console output (optional)\n","  plt.figure(figsize=(10, 5))\n","\n","  plt.subplot(1, 2, 1)\n","  plt.plot(xsens, mu.squeeze(0), '.', label = 'sensors')\n","  plt.title(\"Input $f$\")\n","  plt.legend()\n","\n","  plt.subplot(1, 2, 2)\n","  plt.plot(ygrid, true_u, color = 'orange', label = 'True')\n","  plt.plot(ygrid, pred_u, '--r', label = 'DeepONet')\n","  plt.title(\"Output $u$\")\n","  plt.legend()\n","  None"],"metadata":{"id":"LQIQbyH6SvTH","executionInfo":{"status":"aborted","timestamp":1743928399737,"user_tz":-120,"elapsed":14874,"user":{"displayName":"Gabriele Bruni","userId":"03438434252057538638"}}},"execution_count":null,"outputs":[]}]}